{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import IPython\n",
    "HTML('''<script>\n",
    "code_show=false; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Analysis of deep sequencing data\n",
    "\n",
    "## Ratio-based scores\n",
    "### Prone to sampling error with low frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Method for computing values \n",
    "\n",
    "\n",
    "A frequency of a variant in a time point is defined as the counts of the variant in that time point\n",
    " ($c_{\\nu,t}$) divided by the number of read sequences ($N_{t}$).\n",
    "<br>\n",
    "$\n",
    "f_{\\nu,t} = \\frac{c_{\\nu,t}}{N_{t}}\n",
    "$\n",
    "\n",
    "and the change in ratio frequencies is \n",
    "\n",
    "$\n",
    "r_{\\nu,t} = \\frac{f_{\\nu,t}}{f_{\\nu,0}}\n",
    "$\n",
    "\n",
    "Instead of using this raw change in variant frequency, we divide each variant's ratio with WT ratio \n",
    "\n",
    "\n",
    "$\n",
    "\\frac{r_{\\nu,t}}{r_{wt,t}} = \\frac{c_{\\nu,t}c_{wt,0}}{ c_{\\nu,0}c_{wt,t}  }\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A 1/2 is added to each count to compensate for small numbers of counts and the natural logorithm\n",
    "\n",
    "$\n",
    "L_{\\nu,t} = log( \\frac{(c_{\\nu,t}+1/2)(c_{wt,0}+1/2)}{(c_{\\nu,0}+1/2)(c_{wt,t} + 1/2)}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This can be rewritten\n",
    "<br><br>\n",
    "$\n",
    "M_{\\nu,t} = \\log \\frac{c_{\\nu,t} + 1/2}{c_{wt,t} + 1/2}\n",
    "$\n",
    "<br>\n",
    "<br>\n",
    "To account for unequal information content we perform weigthed linear least squares regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The regression \n",
    "weight for $M_{\\nu,t}$ is $V^{-1}_{\\nu,t}$ where $V_{\\nu,t}$ (based on Poisson assumption)<br><br>\n",
    "\n",
    "$\n",
    "V_{\\nu,t} = \\frac{1}{c_{\\nu,t}+1/2} + \\frac{1}{c_{wt,t}+1/2}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We compute the standard error ($SE_{\\nu}$) for the enrichment score $L_{\\nu}$ under the Poisson assumptions\n",
    "<br><br>\n",
    "$\n",
    "SE_{\\nu} = \\sqrt{ \\frac{1}{c_{\\nu,0}+1/2}+ \\frac{1}{c_{wt,0}+1/2}+ \\frac{1}{c_{\\nu,sel}+1/2}+\\frac{1}{c_{wt,sel}+1/2} }\n",
    "$\n",
    "<br><br>\n",
    "Setting a cutoff of the SE using 2% of the maximum value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We compute a raw-pvalue and z-score for the variants\n",
    "<br><br>\n",
    "$\n",
    "z = \\frac{log_{\\nu} - log_{WT}} {\\sqrt{SE_{\\nu}^2+SE_{WT}^2} }\n",
    "$\n",
    "<br><br>\n",
    "a a raw pvalue is computed\n",
    "<br><br>\n",
    "\n",
    "pvalue = 2*stats.norm.sf(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import plotly\n",
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode() # run at the start of every ipython notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "date = str(20190107)\n",
    "# number of top sequences analysed\n",
    "topseqs = 25\n",
    "# Reference sequence\n",
    "seq =  \"XXXXX\"\n",
    "# WT score and sequence in excel or csv file\n",
    "idx_wt = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"~/pythonscripts\")\n",
    "import RenameRelativeToNativeSeq as rrn\n",
    "r_ = rrn.DiffFasta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_and_compute_z_and_p_value(dftmp,base_score,base_se,col_val=\"log_ratio_3\",col_se=\"se_ratio_3\"):\n",
    "    #col[\"z\"] = np.abs(col['score1'] - col['score2']) / np.sqrt(col['SE1'] ** 2 + col['SE2'] ** 2)\n",
    "    dftmp[\"z\"] = (dftmp[col_val] - base_score) / np.sqrt(dftmp[col_se] ** 2 + base_se ** 2)\n",
    "    dftmp['pvalue_raw'] = 2 * scipy.stats.norm.sf(dftmp['z'])\n",
    "    return dftmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# file with reads\n",
    "df = pd.read_excel(\"NGS_reads.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df.drop(['index'],inplace=True,axis=1)\n",
    "except:\n",
    "    print(\"Already removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# No index has been made e.g. no NNC number\n",
    "df[\"ID\"] = df.index\n",
    "df[\"ID\"] = \"ID_\"+df[\"ID\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# f1 = SORT1 / N\n",
    "# f2 = SORT2 / N\n",
    "# f3 = SORT3 / N\n",
    "df['freq0'] = df['L1-R0'] / df['L1-R0'].sum()\n",
    "df['freq1'] = df['L1-R1'] / df[\"L1-R1\"].sum()\n",
    "df['freq2'] = df['L1-R2'] / df[\"L1-R2\"].sum()\n",
    "df['freq3'] = df['L1-R3'] / df[\"L1-R3\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Compute Lv,t for each of the variants\n",
    "def compute_log_rations(newcol_name, wt_0, col_0, wt_v, col_v,df):\n",
    "    '''\n",
    "    newcol_name : str\n",
    "    wt_0 : float - WT normalized round 0\n",
    "    col_v  : series - variants normalized by total counts\n",
    "    wt_v : float - wt_v in normalized by total counts round t\n",
    "    col_v  : series - variant normalized by total counts round t\n",
    "    df : dataframe\n",
    "    '''\n",
    "    pseudo_count = 0.5\n",
    "    df[newcol_name] = np.log10( ((df[col_v] + pseudo_count)*(wt_0+pseudo_count)) /((df[col_0] + pseudo_count)*(wt_v+pseudo_count))).round(3)\n",
    "    return df\n",
    "\n",
    "# insert from file \n",
    "wt_0 = 0000\n",
    "wt_1 = 0000\n",
    "wt_2 = 0000\n",
    "wt_3 = 0000\n",
    "df = compute_log_rations('log_ratio_1',wt_0,'L1-R0',wt_1,'L1-R1',df )\n",
    "df = compute_log_rations('log_ratio_2',wt_0,'L1-R0',wt_2,'L1-R2',df )\n",
    "df = compute_log_rations('log_ratio_3',wt_0,'L1-R0',wt_3,'L1-R3',df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def compute_se(newcol_name, col_v, wt_v,df):\n",
    "    '''\n",
    "    newcol_name : str\n",
    "    wt_0 : float - WT normalized round 0\n",
    "    col_v  : series - variants normalized by total counts\n",
    "    wt_v : float - wt_v in normalized by total counts round t\n",
    "    col_v  : series - variant normalized by total counts round t\n",
    "    df : dataframe\n",
    "    '''\n",
    "    pseudo_count = 0.5\n",
    "    df[newcol_name] = np.sqrt( (1 / (df[col_v] + pseudo_count)) +  (1 / (wt_v+pseudo_count))   )\n",
    "    return df\n",
    "\n",
    "wt_0 = 5461\n",
    "wt_1 = 15117\n",
    "wt_2 = 20667\n",
    "wt_3 = 7396\n",
    "\n",
    "df = compute_se('se_ratio_1','L1-R0',wt_1,df)\n",
    "df = compute_se('se_ratio_2','L1-R0',wt_2,df)\n",
    "df = compute_se('se_ratio_3','L1-R0',wt_3,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Removes counts less than 10\n",
    "count_threshold = 10\n",
    "count_sort_threshold = 'L1-R0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "ori_df = df.copy()\n",
    "df = df[df[count_sort_threshold] > count_threshold].copy()\n",
    "df.sort_values(by=\"freq3\",inplace=True,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "try:\n",
    "    df.drop(['index'],inplace=True,axis=1)\n",
    "except:\n",
    "    print(\"Already removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# insert column with mutational difference to sequence\n",
    "    \n",
    "df[\"Muts\"] = \"\"\n",
    "for i,j in zip(df.index,df[\"SEQS\"]):\n",
    "    diff_ = r_.diff_sequence_a_b(seq,j)\n",
    "    df.iloc[i, df.columns.get_loc(\"Muts\")] = diff_[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_score =  df.iloc[idx_wt,df.columns.get_loc(\"log_ratio_3\")]\n",
    "base_se = df.iloc[idx_wt,df.columns.get_loc(\"se_ratio_3\")]\n",
    "df = get_and_compute_z_and_p_value(df,base_score,base_se,col_val=\"log_ratio_3\",col_se=\"se_ratio_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "tmp = df[[\"ID\",\"Muts\",\"log_ratio_1\",\"log_ratio_2\",\"log_ratio_3\",\"se_ratio_1\",\"se_ratio_2\",\"se_ratio_3\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tmp.drop(\"index\",inplace=True)\n",
    "except:\n",
    "    print(\"Not present\")\n",
    "tmp = pd.melt(tmp,id_vars=[\"ID\",\"Muts\"],value_vars=[\"log_ratio_1\",\"log_ratio_2\",\"log_ratio_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "tmp[\"Round\"] = 0\n",
    "for i,j in zip(tmp.index,tmp.variable):\n",
    "    if(j == \"log_ratio_1\" ):\n",
    "        tmp.iloc[i, tmp.columns.get_loc(\"Round\")] = 1\n",
    "    elif(j == \"log_ratio_2\"):\n",
    "        tmp.iloc[i, tmp.columns.get_loc(\"Round\")] = 2\n",
    "    elif(j == \"log_ratio_3\"):\n",
    "        tmp.iloc[i, tmp.columns.get_loc(\"Round\")] = 3\n",
    "    else:\n",
    "        print(\"Error\",j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sequence significantly better than WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Get sequences significant better than WT\n",
    "df_sig = df[(df[\"z\"] > 0) & (df[\"pvalue_raw\"] < 0.05) & (df['log_ratio_1'] > 0.0) & (df['log_ratio_2'] > 0.0) & (df['log_ratio_3'] >= 1.0)  ]\n",
    "df_sig.sort_values(by=['log_ratio_3'],ascending=False).to_excel(date+\"significant_hits.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sig.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(date+\"significant_hits.fasta\",'w') as f:\n",
    "    for i,j in zip(df_sig[\"Muts\"],df_sig['SEQS']):\n",
    "        f.write(\">\"+i+\"\\n\")\n",
    "        f.write(j+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of significant hits: \",len(df_sig.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot ratios\n",
    "data = []\n",
    "# top 50 \n",
    "for i in tmp[0:topseqs].ID:\n",
    "    t_ = tmp[(tmp[\"ID\"] == i)]\n",
    "    data.append(go.Scatter(x=t_[\"Round\"],y=t_[\"value\"],mode='lines+markers',\\\n",
    "                       text=t_[\"ID\"]+\"<br>Muts: \"+t_[\"Muts\"],\\\n",
    "                           marker=dict(size=10),\\\n",
    "                           #name=\"ID: \"+t_[\"ID\"].astype(str),\\\n",
    "                          ))\n",
    "\n",
    "layout = go.Layout(title=\"NGS Optimization\",\\\n",
    "    xaxis=dict(title='Sorting rounds',\n",
    "               titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Ratio (Round 3 normalized) ',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f')))\n",
    "fig = go.Figure(data=data,layout=layout)\n",
    "offline.iplot(fig, filename=date+\"_per_variant_lineplot.png\",image='png')\n",
    "offline.plot(fig, filename=date+\"_per_variant_lineplot.html\",auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Heat map\n",
    "# create_annotated_heatmap\n",
    "trace = go.Heatmap(z=tmp[\"value\"],\n",
    "                   x=tmp[u'Round'],\n",
    "                   y=tmp[u'ID'],\n",
    "                   hoverinfo='text',\n",
    "                    text=\"ID: \"+tmp[\"ID\"].astype(str)+\" \\n Enrichment value: \"+tmp[\"value\"].astype(str)+\"\\nMuts: \"+tmp[\"Muts\"]\n",
    "            )\n",
    "layout = go.Layout(width=1000,\n",
    "                   height=1000,\n",
    "                   margin=go.Margin(\n",
    "                   pad=5,b=100,r=20\n",
    "                   ),xaxis=dict(autorange=True,\n",
    "                                tickfont=dict(size=8)),\n",
    "                   yaxis=dict(title=\"Seq ID\",tickfont=dict(size=8) )\n",
    "                  )\n",
    "fig = go.Figure(data=[trace],layout=layout)\n",
    "offline.iplot(fig, filename=\"heatmap_test\")\n",
    "offline.plot(fig, filename=\"heatmap.html\",auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def get_enrichments_ratios(wt_seq,sequence_column_name,value_1,df):\n",
    "    import sys\n",
    "    sys.path.append(\"~/pythonscripts/\")\n",
    "    import RenameRelativeToNativeSeq as rrn\n",
    "    r_ = rrn.DiffFasta()\n",
    "    df_aa_enrichments = {}\n",
    "    df_seq_ids = {}\n",
    "    for i,j,l in zip(df[sequence_column_name],df[value_1],df.ID ):\n",
    "        diff_ = r_.diff_sequence_a_b(wt_seq,i)\n",
    "        diff_ = diff_.replace(\"_\",\",\")\n",
    "        if(diff_ == \"\"):\n",
    "            # print(\"no diff\")\n",
    "            continue\n",
    "        if(diff_[-1] == \",\"):\n",
    "            for k in diff_[0:-1].split(','):\n",
    "                if( k not in df_aa_enrichments.keys() ):\n",
    "                    df_aa_enrichments[k] = []    \n",
    "                    df_seq_ids[k] = \"\"\n",
    "                df_aa_enrichments[k].append(j)\n",
    "                df_seq_ids[k] = df_seq_ids[k]+str(l)+\",\"\n",
    "    return df_aa_enrichments,df_seq_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Computing the xxx \n",
    "values_, counts_ = get_enrichments_ratios(seq,\"SEQS\",\"log_ratio_3\",df[0:topseqs])\n",
    "dftmp1_ = pd.DataFrame(list(values_.items()), columns=['Mut_Id', \"u(log_ratio)\"])\n",
    "dftmp2_ = pd.DataFrame(list(counts_.items()), columns=['Mut_Id', \"seqIDs\"])\n",
    "dfval = pd.merge(right=dftmp1_,right_on=\"Mut_Id\",left=dftmp2_,left_on=\"Mut_Id\")\n",
    "\n",
    "for i,j in zip(dfval.index,dfval[\"u(log_ratio)\"]):\n",
    "    dfval.iloc[i,dfval.columns.get_loc(\"u(log_ratio)\")] = round(np.mean(j),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Per position and amino acid\n",
    "df_aa = pd.DataFrame(index=range(0,20*len(seq)),columns=[\"AA\",\"Pos\",\"WT\"])\n",
    "AA = ['W','V','L','I','M','F','Y','Q','N','T','R','S','K','E','D','H','C','P','G','A']\n",
    "idx_ = -1\n",
    "for i in range(len(seq)):\n",
    "    pos_ = i+1\n",
    "    for aa in range(len(AA)):\n",
    "        idx_ = idx_+ 1\n",
    "        df_aa.iloc[idx_,df_aa.columns.get_loc(\"WT\")] = seq[i]\n",
    "        df_aa.iloc[idx_,df_aa.columns.get_loc(\"Pos\")] = str(pos_)\n",
    "        df_aa.iloc[idx_,df_aa.columns.get_loc(\"AA\")] = AA[aa]\n",
    "df_aa['Mut_Id'] = df_aa[\"WT\"]+df_aa[\"Pos\"]+df_aa[\"AA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "hm_ = pd.merge(right=df_aa, right_on=\"Mut_Id\",left=dfval,left_on=\"Mut_Id\",how='right') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#create_annotated_heatmap\n",
    "trace = go.Heatmap(z=hm_[\"u(log_ratio)\"],\n",
    "                   x=hm_[\"Pos\"],\n",
    "                   y=hm_[\"AA\"],\n",
    "                   hoverinfo='text',\n",
    "                   text=\"WT: \"+hm_[\"WT\"]+\"\\nPos: \"+hm_[\"Pos\"]+\"\\nMut: \"+hm_['Mut_Id']+\"\\nSeqs: \"+hm_[\"seqIDs\"]+\"\\nlog_mean: \"+hm_[\"u(log_ratio)\"].apply(str)\n",
    "                  )\n",
    "layout = go.Layout(width=1000,\n",
    "                   height=500,\n",
    "                   margin=go.Margin(\n",
    "                   pad=5,b=100,r=20\n",
    "                   ),xaxis=dict(autorange=True,title=\"Position\",\n",
    "                                tickfont=dict(size=12),showgrid=False),\n",
    "                   yaxis=dict(tickfont=dict(size=12),title=\"AA\",\\\n",
    "                              categoryorder='array',categoryarray=AA,showgrid=False))\n",
    "fig = go.Figure(data=[trace],layout=layout)\n",
    "offline.iplot(fig, filename=date+\"_per_AA.png\")\n",
    "offline.plot(fig, filename=date+\"_per_AA.html\",auto_open=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "## enriched/depleted sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Get sequences significant better than WT\n",
    "df_sig = df[(df[\"z\"] > 0) & (df[\"pvalue_raw\"] < 0.05) ]\n",
    "df_sig.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Per amino acid activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# cutoff value for \n",
    "base_se = 2*(df.iloc[0,df.columns.get_loc(\"se_ratio_3\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "aa_sig = hm_[(hm_[\"u(log_ratio)\"] > base_se)]\n",
    "aa_sig = aa_sig.sort_values(by=\"u(log_ratio)\",ascending=False)\n",
    "aa_sig.to_excel(\"AAsign.xlsx\",index=False)\n",
    "aa_sig.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(date+\"_significant_hits.fasta\",'w') as f:\n",
    "    for i,j in zip(df_sig.Muts,df_sig['SEQS']):\n",
    "        f.write(\">\"+i+\"\\n\")\n",
    "        f.write(j+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(date+\"_highest_counts_hits.fasta\",'w') as f:\n",
    "    tmp = [0,1,2]\n",
    "    for i in tmp:\n",
    "        j = ori_df.iloc[i,ori_df.columns.get_loc('SEQS' ) ]\n",
    "        diff_ = r_.diff_sequence_a_b(seq,j)\n",
    "        print(str(i)+\": \"+diff_)\n",
    "        f.write(\">\"+str(diff_)+\"\\n\")\n",
    "        f.write(seq+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
